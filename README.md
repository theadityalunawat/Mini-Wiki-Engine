#Mini Search Engine

This program code uses large data dump of Wiki-pedia and creates a search module similar to the wiki search.
The time boundation for a min. 10 word query is less than 10 seconds.
The dump can be downloaded from the below link:
http://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2
It uses SAX parser to parse the dump-XML file and create an index(Primary index).
This index is further broken down tos secondry index and third level index.
The three indices are used for mapping a page from the dump.
It is built on Java.

It includes the following modules:
1) Primary index creation module is used to create a primary index of the large data.
2) Query Parser module is used to parse a particular query after generating the indices.
3) Simple tag wise and occurance wise word calculation is used to count the relevancy of a particular word
